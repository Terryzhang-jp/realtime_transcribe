// éŸ³é¢‘å½•åˆ¶å™¨

export interface AudioDevice {
  deviceId: string;
  label: string;
}

export class AudioRecorder {
  private mediaRecorder: MediaRecorder | null = null;
  private stream: MediaStream | null = null;
  private onDataCallback: ((data: Blob) => void) | null = null;
  private audioContext: AudioContext | null = null;
  private processor: ScriptProcessorNode | null = null;
  private source: MediaStreamAudioSourceNode | null = null;

  /**
   * è·å–æ‰€æœ‰å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡
   */
  static async getAudioDevices(): Promise<AudioDevice[]> {
    try {
      // å…ˆè¯·æ±‚ä¸€æ¬¡æƒé™ï¼Œå¦åˆ™ enumerateDevices å¯èƒ½è¿”å›ç©º label
      await navigator.mediaDevices.getUserMedia({ audio: true });

      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioDevices = devices
        .filter(device => device.kind === 'audioinput')
        .map(device => ({
          deviceId: device.deviceId,
          label: device.label || `éº¦å…‹é£ ${device.deviceId.slice(0, 5)}`,
        }));

      console.log('ğŸ¤ Available audio devices:', audioDevices);
      return audioDevices;
    } catch (error) {
      console.error('âŒ Failed to get audio devices:', error);
      return [];
    }
  }

  async start(onData: (data: Blob) => void, deviceId?: string) {
    try {
      console.log('ğŸ¤ Requesting microphone access...', deviceId ? `deviceId: ${deviceId}` : 'default device');

      // è¯·æ±‚éº¦å…‹é£æƒé™ - ä½¿ç”¨æ›´ç®€å•çš„çº¦æŸ
      const constraints: MediaStreamConstraints = {
        audio: deviceId ? {
          deviceId: { exact: deviceId },
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        } : {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        }
      };

      this.stream = await navigator.mediaDevices.getUserMedia(constraints);

      // æ£€æŸ¥å®é™…è·å¾—çš„éŸ³é¢‘è½¨é“è®¾ç½®
      const audioTrack = this.stream.getAudioTracks()[0];
      const settings = audioTrack.getSettings();
      console.log('ğŸ¤ Audio track settings:', {
        sampleRate: settings.sampleRate,
        channelCount: settings.channelCount,
        deviceId: settings.deviceId,
        echoCancellation: settings.echoCancellation,
        noiseSuppression: settings.noiseSuppression,
        autoGainControl: settings.autoGainControl,
      });

      console.log('âœ… Microphone access granted');
      this.onDataCallback = onData;

      // ä½¿ç”¨ AudioContext æ¥å¤„ç†éŸ³é¢‘å¹¶è½¬æ¢ä¸º PCM
      // è¿™æ ·å¯ä»¥æ›´å¥½åœ°æ§åˆ¶éŸ³é¢‘æ ¼å¼ï¼Œç¡®ä¿ Soniox å…¼å®¹æ€§
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 16000, // å¼ºåˆ¶ 16kHz é‡‡æ ·ç‡
      });

      console.log('ğŸµ AudioContext sample rate:', this.audioContext.sampleRate);

      this.source = this.audioContext.createMediaStreamSource(this.stream);

      // ä½¿ç”¨ ScriptProcessorNodeï¼ˆè™½ç„¶å·²åºŸå¼ƒï¼Œä½†å…¼å®¹æ€§æœ€å¥½ï¼‰
      // bufferSize: 4096 æ ·æœ¬ â‰ˆ 256ms @ 16kHz
      const bufferSize = 4096;
      this.processor = this.audioContext.createScriptProcessor(bufferSize, 1, 1);

      this.processor.onaudioprocess = (e) => {
        const inputData = e.inputBuffer.getChannelData(0); // Float32Array

        // è½¬æ¢ä¸º Int16 PCM
        const pcmData = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          // Float32 (-1.0 to 1.0) è½¬æ¢ä¸º Int16 (-32768 to 32767)
          const s = Math.max(-1, Math.min(1, inputData[i]));
          pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }

        // è½¬æ¢ä¸º Blob
        const blob = new Blob([pcmData.buffer], { type: 'audio/pcm' });
        console.log('ğŸµ Audio data available (PCM):', blob.size, 'bytes');

        if (this.onDataCallback) {
          this.onDataCallback(blob);
        }
      };

      this.source.connect(this.processor);
      this.processor.connect(this.audioContext.destination);

      console.log('âœ… Recording started with PCM format (16-bit, 16kHz, mono)');

      return true;
    } catch (error) {
      console.error('âŒ Failed to start audio recorder:', error);
      throw error;
    }
  }

  stop() {
    // æ¸…ç† AudioContext ç›¸å…³èµ„æº
    if (this.processor) {
      this.processor.disconnect();
      this.processor = null;
    }

    if (this.source) {
      this.source.disconnect();
      this.source = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }

    // æ¸…ç† MediaRecorderï¼ˆå¦‚æœä½¿ç”¨äº†ï¼‰
    if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
      this.mediaRecorder.stop();
    }

    // åœæ­¢éŸ³é¢‘æµ
    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }

    this.mediaRecorder = null;
    this.onDataCallback = null;
  }

  isRecording(): boolean {
    return this.processor !== null || this.mediaRecorder?.state === 'recording';
  }

  private getSupportedMimeType(): string {
    // æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥æµè§ˆå™¨æ”¯æŒçš„ç¼–ç æ ¼å¼
    const types = [
      'audio/webm;codecs=opus',
      'audio/ogg;codecs=opus',
      'audio/webm',
      'audio/ogg',
    ];

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        console.log('Using MIME type:', type);
        return type;
      }
    }

    // é™çº§åˆ°é»˜è®¤
    return '';
  }
}
